{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3387369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import pandas_ta as ta\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import tensortrade.env.default as default\n",
    "\n",
    "from tensortrade.feed.core import DataFeed, Stream\n",
    "from tensortrade.oms.exchanges import Exchange,ExchangeOptions\n",
    "from tensortrade.oms.services.execution.simulated import execute_order\n",
    "from tensortrade.oms.wallets import Wallet, Portfolio\n",
    "from tensortrade.env.default.rewards import TensorTradeRewardScheme\n",
    "from tensortrade.feed.core import Stream, DataFeed\n",
    "\n",
    "from gym.spaces import Discrete\n",
    "from tensortrade.env.default.actions import TensorTradeActionScheme\n",
    "from tensortrade.env.generic import ActionScheme, TradingEnv\n",
    "from tensortrade.core import Clock\n",
    "from tensortrade.oms.instruments import ExchangePair, Instrument\n",
    "from tensortrade.oms.wallets import Portfolio\n",
    "from tensortrade.oms.orders import (\n",
    "    Order,\n",
    "    proportion_order,\n",
    "    TradeSide,\n",
    "    TradeType\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensortrade.env.generic import Renderer\n",
    "\n",
    "import ray.rllib.agents.ppo as ppo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91f85ad",
   "metadata": {},
   "source": [
    "### Action Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de0d32e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BSH(TensorTradeActionScheme):\n",
    "    \"\"\"The ActionScheme interprets and applies the agent’s actions to the environment.\"\"\"\n",
    "\n",
    "    registered_name = \"bsh\"\n",
    "\n",
    "    def __init__(self, cash: 'Wallet', asset: 'Wallet'):\n",
    "        super().__init__()\n",
    "        self.cash = cash\n",
    "        self.asset = asset\n",
    "\n",
    "        self.listeners = []\n",
    "        self.action = 0\n",
    "\n",
    "    @property\n",
    "    def action_space(self):\n",
    "        return Discrete(2)\n",
    "\n",
    "    def attach(self, listener):\n",
    "        self.listeners += [listener]\n",
    "        return self\n",
    "\n",
    "    def get_orders(self, action: int, portfolio: 'Portfolio'):\n",
    "        order = None\n",
    "\n",
    "        if abs(action - self.action) > 0:\n",
    "            src = self.cash if self.action == 0 else self.asset\n",
    "            tgt = self.asset if self.action == 0 else self.cash\n",
    "            order = proportion_order(portfolio, \n",
    "                                     src, \n",
    "                                     tgt, \n",
    "                                     1.0)\n",
    "            self.action = action\n",
    "\n",
    "        for listener in self.listeners:\n",
    "            listener.on_action(action)\n",
    "\n",
    "        return [order]\n",
    "\n",
    "    def reset(self):\n",
    "        super().reset()\n",
    "        self.action = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f99033",
   "metadata": {},
   "source": [
    "### Reward Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c6d815a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PBR(TensorTradeRewardScheme):\n",
    "\n",
    "    \"\"\" Position-based reward scheme (PBR).\n",
    "    \n",
    "    The RewardScheme computes the reward for \n",
    "    each time step based on the agent’s performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    registered_name = \"pbr\"\n",
    "\n",
    "    def __init__(self, price: 'Stream'):\n",
    "        super().__init__()\n",
    "        self.position = -1\n",
    "\n",
    "        r = Stream.sensor(price, lambda p: p.value, dtype=\"float\").diff()\n",
    "        position = Stream.sensor(self, lambda rs: rs.position, dtype=\"float\")\n",
    "\n",
    "        reward = (r * position).fillna(0).rename(\"reward\")\n",
    "\n",
    "        self.feed = DataFeed([reward])\n",
    "        self.feed.compile()\n",
    "\n",
    "    def on_action(self, action: int):\n",
    "        self.position = -1 if action == 0 else 1\n",
    "\n",
    "    def get_reward(self, portfolio: 'Portfolio'):\n",
    "        return self.feed.next()[\"reward\"]\n",
    "\n",
    "    def reset(self):\n",
    "        self.position = -1\n",
    "        self.feed.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd2fb17",
   "metadata": {},
   "source": [
    "### Renderer (Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4e0a4b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionChangeChart(Renderer):\n",
    "    \"\"\"The Renderer renders a view of the environment and interactions.\"\"\"\n",
    "    \n",
    "    def __init__(self, color: str = \"orange\"):\n",
    "        self.color = \"orange\"\n",
    "\n",
    "    def render(self, env, **kwargs):\n",
    "        # The Observer generates the next observation for the agent.\n",
    "        history = pd.DataFrame(env.observer.renderer_history)\n",
    "\n",
    "        actions = list(history.action)\n",
    "        p = list(history.price)\n",
    "\n",
    "        buy = {}\n",
    "        sell = {}\n",
    "\n",
    "        for i in range(len(actions) - 1):\n",
    "            a1 = actions[i]\n",
    "            a2 = actions[i + 1]\n",
    "\n",
    "            if a1 != a2:\n",
    "                if a1 == 0 and a2 == 1:\n",
    "                    buy[i] = p[i]\n",
    "                else:\n",
    "                    sell[i] = p[i]\n",
    "\n",
    "        buy = pd.Series(buy)\n",
    "        sell = pd.Series(sell)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        fig.suptitle(\"Performance\")\n",
    "\n",
    "        axs[0].plot(np.arange(len(p)), p, label=\"price\", color=self.color)\n",
    "        axs[0].scatter(buy.index, buy.values, marker=\"v\", color=\"red\") # BUY\n",
    "        axs[0].scatter(sell.index, sell.values, marker=\"^\", color=\"green\") # SELL\n",
    "        axs[0].set_title(\"Trading Chart\")\n",
    "        axs[0].legend(['Price', 'Buys', 'Sells'])\n",
    "\n",
    "        performance_df = pd.DataFrame().from_dict(env.action_scheme.portfolio.performance, orient='index')\n",
    "        performance_df.plot(ax=axs[1])\n",
    "        axs[1].set_title(\"Net Worth\")\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9515476a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c333762d",
   "metadata": {},
   "source": [
    "### DRL Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed89af5",
   "metadata": {},
   "source": [
    "### Train\n",
    "\n",
    "Now in order to use our custom environment in ray we must first write a function that creates an instance of the TradingEnv from a configuration dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11bee78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_test_datasets(ticker, train_test_split):\n",
    "    \"\"\"Get Yahoo! Finance Data for Train/Test Splits.\"\"\"\n",
    "\n",
    "    yf_ticker = yf.Ticker(ticker=f'{ticker}.SA')\n",
    "\n",
    "    df = yf_ticker.history(period='1y', interval='1h')\n",
    "    df.drop(['Dividends', 'Stock Splits'], axis=1, inplace=True)\n",
    "    df[\"Volume\"] = df[\"Volume\"].fillna(0).astype(int)\n",
    "    df.ta.log_return(append=True, length=16)\n",
    "    df.ta.rsi(append=True, length=14)\n",
    "    df.ta.macd(append=True, fast=12, slow=26)\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    next_day = datetime.strptime(train_test_split, '%Y-%m-%d')\n",
    "    next_day = next_day + timedelta(days=1)\n",
    "    next_day = next_day.strftime('%Y-%m-%d')\n",
    "\n",
    "    df_training = df.loc[:train_test_split].copy()\n",
    "    df_evaluation = df.loc[next_day:].copy()\n",
    "\n",
    "    df_training.dropna().to_csv('training.csv', index=True)\n",
    "    df_evaluation.dropna().to_csv('evaluation.csv', index=True)\n",
    "\n",
    "    return df_training, df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f800b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = generate_train_test_datasets('PETR4', '2021-08-27')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83c625a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>LOGRET_16</th>\n",
       "      <th>RSI_14</th>\n",
       "      <th>MACD_12_26_9</th>\n",
       "      <th>MACDh_12_26_9</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-04-29 12:00:00-03:00</th>\n",
       "      <td>23.650000</td>\n",
       "      <td>23.870001</td>\n",
       "      <td>23.52</td>\n",
       "      <td>23.559999</td>\n",
       "      <td>9092100</td>\n",
       "      <td>-0.021831</td>\n",
       "      <td>46.140399</td>\n",
       "      <td>-0.022248</td>\n",
       "      <td>0.045665</td>\n",
       "      <td>-0.067913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 13:00:00-03:00</th>\n",
       "      <td>23.540001</td>\n",
       "      <td>23.690001</td>\n",
       "      <td>23.42</td>\n",
       "      <td>23.650000</td>\n",
       "      <td>5120500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>49.323374</td>\n",
       "      <td>-0.022463</td>\n",
       "      <td>0.036360</td>\n",
       "      <td>-0.058823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 14:00:00-03:00</th>\n",
       "      <td>23.650000</td>\n",
       "      <td>23.690001</td>\n",
       "      <td>23.50</td>\n",
       "      <td>23.650000</td>\n",
       "      <td>3363000</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>49.323374</td>\n",
       "      <td>-0.022376</td>\n",
       "      <td>0.029158</td>\n",
       "      <td>-0.051534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 15:00:00-03:00</th>\n",
       "      <td>23.650000</td>\n",
       "      <td>23.730000</td>\n",
       "      <td>23.58</td>\n",
       "      <td>23.620001</td>\n",
       "      <td>2948600</td>\n",
       "      <td>0.008503</td>\n",
       "      <td>48.221726</td>\n",
       "      <td>-0.024445</td>\n",
       "      <td>0.021671</td>\n",
       "      <td>-0.046116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-04-29 16:00:00-03:00</th>\n",
       "      <td>23.620001</td>\n",
       "      <td>23.629999</td>\n",
       "      <td>23.50</td>\n",
       "      <td>23.580000</td>\n",
       "      <td>9928500</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>46.723170</td>\n",
       "      <td>-0.028979</td>\n",
       "      <td>0.013710</td>\n",
       "      <td>-0.042689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Open       High    Low      Close   Volume  \\\n",
       "2021-04-29 12:00:00-03:00  23.650000  23.870001  23.52  23.559999  9092100   \n",
       "2021-04-29 13:00:00-03:00  23.540001  23.690001  23.42  23.650000  5120500   \n",
       "2021-04-29 14:00:00-03:00  23.650000  23.690001  23.50  23.650000  3363000   \n",
       "2021-04-29 15:00:00-03:00  23.650000  23.730000  23.58  23.620001  2948600   \n",
       "2021-04-29 16:00:00-03:00  23.620001  23.629999  23.50  23.580000  9928500   \n",
       "\n",
       "                           LOGRET_16     RSI_14  MACD_12_26_9  MACDh_12_26_9  \\\n",
       "2021-04-29 12:00:00-03:00  -0.021831  46.140399     -0.022248       0.045665   \n",
       "2021-04-29 13:00:00-03:00   0.000000  49.323374     -0.022463       0.036360   \n",
       "2021-04-29 14:00:00-03:00   0.008493  49.323374     -0.022376       0.029158   \n",
       "2021-04-29 15:00:00-03:00   0.008503  48.221726     -0.024445       0.021671   \n",
       "2021-04-29 16:00:00-03:00   0.012804  46.723170     -0.028979       0.013710   \n",
       "\n",
       "                           MACDs_12_26_9  \n",
       "2021-04-29 12:00:00-03:00      -0.067913  \n",
       "2021-04-29 13:00:00-03:00      -0.058823  \n",
       "2021-04-29 14:00:00-03:00      -0.051534  \n",
       "2021-04-29 15:00:00-03:00      -0.046116  \n",
       "2021-04-29 16:00:00-03:00      -0.042689  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa052df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open\n",
      "High\n",
      "Low\n",
      "Close\n",
      "Volume\n",
      "LOGRET_16\n",
      "RSI_14\n",
      "MACD_12_26_9\n",
      "MACDh_12_26_9\n",
      "MACDs_12_26_9\n"
     ]
    }
   ],
   "source": [
    "for c in df_train.columns:\n",
    "    print (c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691c5962",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d3b8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_env(config):\n",
    "    \"\"\"Creates Trading Environment. \"\"\"\n",
    "    \n",
    "    ticker = 'PETR4'\n",
    "    \n",
    "    dataset = pd.read_csv(filepath_or_buffer=\"C:\\\\Users\\\\mathe\\\\Desktop\\\\Desktop\\\\Estudos\\\\Courses\\\\(Framework) TensorTrade\\\\training.csv\", \n",
    "                          parse_dates=True).fillna(method='backfill').fillna(method='ffill')\n",
    "    \n",
    "    # Price Series\n",
    "    price = Stream.source(list(dataset[\"Close\"]), dtype=\"float\").rename(\"BRL-ASSETS\")\n",
    "    \n",
    "    b3_commission = 0.0035\n",
    "    b3_options = ExchangeOptions(commission=b3_commission)\n",
    "    b3_exchange = Exchange(\"B3\", service=execute_order, options=b3_options)(price)\n",
    "    \n",
    "    # Instruments\n",
    "    BRL = Instrument(\"BRL\", 2, \"Brazilian Currency\")\n",
    "    ASSETS = Instrument(\"ASSETS\", 2, \"Assets\")\n",
    "\n",
    "    # Portfolio\n",
    "    cash = Wallet(b3_exchange, 10000 * BRL) # Money\n",
    "    asset = Wallet(b3_exchange, 0 * ASSETS) # Stocks/Assets\n",
    "    \n",
    "    portfolio = Portfolio(BRL, [cash, asset])\n",
    "    \n",
    "    features = []\n",
    "    for c in dataset.columns[1:]:\n",
    "        s = Stream.source(list(dataset[c]), dtype=\"float\").rename(dataset[c].name)\n",
    "        features += [s]\n",
    "    feed = DataFeed(features)\n",
    "    feed.compile()\n",
    "    \n",
    "    # Rewards\n",
    "    reward_scheme = default.rewards.RiskAdjustedReturns(\n",
    "        return_algorithm='sharpe',\n",
    "        risk_free_rate=0.0005,\n",
    "        window_size=7*5\n",
    "    )\n",
    "    \n",
    "    # Actions\n",
    "    action_scheme = default.actions.ManagedRiskOrders(\n",
    "        stop=[0.05],\n",
    "        take=[0.075],\n",
    "        min_order_pct=0.5\n",
    "    )\n",
    "    \n",
    "    # Visualization\n",
    "    renderer_feed = DataFeed([\n",
    "        Stream.source(list(dataset.index)).rename(\"date\"),\n",
    "        Stream.source(list(dataset[\"Close\"]), dtype=\"float\").rename(\"price\"),\n",
    "        Stream.sensor(action_scheme.broker, lambda b: len(b.unexecuted), dtype=\"float\").rename(\"action\")\n",
    "    ])\n",
    "\n",
    "    environment = default.create(\n",
    "        feed=feed,\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=action_scheme,\n",
    "        reward_scheme=reward_scheme,\n",
    "        renderer_feed=renderer_feed,\n",
    "        renderer=PositionChangeChart(),\n",
    "        window_size=config[\"window_size\"],\n",
    "        max_allowed_loss=0.4\n",
    "    )\n",
    "    \n",
    "    return environment\n",
    "\n",
    "register_env(\"TradingEnv\", create_training_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52242db7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378d70d1",
   "metadata": {},
   "source": [
    "Now that the environment is registered we can run the training algorithm using the Proximal Policy Optimization (PPO) algorithm implemented in rllib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62bccd9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=23632)\u001b[0m 2022-04-22 14:14:34,233\tINFO trainer.py:712 -- Executing eagerly (framework='tf2'), with eager_tracing=True. For production workloads, make sure to set `eager_tracing=True` in order to match the speed of tf-static-graph (framework='tf'). For debugging purposes, `eager_tracing=False` is the best choice.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-04-22 14:14:44 (running for 00:00:19.99)<br>Memory usage on this node: 15.5/15.9 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 2.0/24 CPUs, 1.0/2 GPUs, 0.0/6.7 GiB heap, 0.0/3.35 GiB objects<br>Result logdir: C:\\Users\\mathe\\ray_results\\MyExperiment1<br>Number of trials: 1/1 (1 RUNNING)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_a84c7_00000</td><td>RUNNING </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 14:14:44,289\tERROR trial_runner.py:958 -- Trial PPO_TradingEnv_a84c7_00000: Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\tune\\trial_runner.py\", line 924, in _process_trial\n",
      "    results = self.trial_executor.fetch_result(trial)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\tune\\ray_trial_executor.py\", line 787, in fetch_result\n",
      "    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\worker.py\", line 1715, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=23632, ip=127.0.0.1)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 625, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      "  File \"python\\ray\\_raylet.pyx\", line 578, in ray._raylet.execute_task.function_executor\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 609, in actor_method_executor\n",
      "    return method(__ray_actor, *args, **kwargs)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 102, in __init__\n",
      "    Trainer.__init__(self, config, env, logger_creator,\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 661, in __init__\n",
      "    super().__init__(config, logger_creator, remote_checkpoint_dir,\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\tune\\trainable.py\", line 121, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 113, in setup\n",
      "    super().setup(config)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 764, in setup\n",
      "    self._init(self.config, self.env_creator)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 136, in _init\n",
      "    self.workers = self._make_workers(\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      "    return method(self, *_args, **_kwargs)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 1727, in _make_workers\n",
      "    return WorkerSet(\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\", line 87, in __init__\n",
      "    remote_spaces = ray.get(self.remote_workers(\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\worker.py\", line 1713, in get\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RayOutOfMemoryError): \u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=24456, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000239D83C5C70>)\n",
      "  File \"python\\ray\\_raylet.pyx\", line 585, in ray._raylet.execute_task\n",
      "  File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 156, in raise_if_low_memory\n",
      "    raise RayOutOfMemoryError(\n",
      "ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-625611C is used (15.59 / 15.86 GB). The top 10 memory consumers are:\n",
      "\n",
      "PID\tMEM\tCOMMAND\n",
      "16600\t2.88GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe -m ipykernel_launcher --ip=127.0.0.1 --stdin=9014 --cont\n",
      "1776\t1.95GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --type=renderer --user-data-dir=C:\\\n",
      "19044\t1.83GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      "24456\t0.78GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      "36580\t0.45GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe -m ipykernel_launcher --ip=127.0.0.1 --stdin=9019 --cont\n",
      "23632\t0.41GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      "16340\t0.26GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --type=renderer --user-data-dir=C:\\\n",
      "13716\t0.21GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      "17216\t0.19GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --ms-enable-electron-run-as-node c:\n",
      "10024\t0.18GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --ms-enable-electron-run-as-node c:\n",
      "\n",
      "In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      "---\n",
      "--- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      "--- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      "---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for PPO_TradingEnv_a84c7_00000:\n",
      "  trial_id: a84c7_00000\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-04-22 14:14:44 (running for 00:00:20.00)<br>Memory usage on this node: 15.5/15.9 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/2 GPUs, 0.0/6.7 GiB heap, 0.0/3.35 GiB objects<br>Result logdir: C:\\Users\\mathe\\ray_results\\MyExperiment1<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_a84c7_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_a84c7_00000</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\mathe\\ray_results\\MyExperiment1\\PPO_TradingEnv_a84c7_00000_0_2022-04-22_14-14-24\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "== Status ==<br>Current time: 2022-04-22 14:14:44 (running for 00:00:20.00)<br>Memory usage on this node: 15.5/15.9 GiB: ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.<br>Using FIFO scheduling algorithm.<br>Resources requested: 0/24 CPUs, 0/2 GPUs, 0.0/6.7 GiB heap, 0.0/3.35 GiB objects<br>Result logdir: C:\\Users\\mathe\\ray_results\\MyExperiment1<br>Number of trials: 1/1 (1 ERROR)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th>status  </th><th>loc  </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_a84c7_00000</td><td>ERROR   </td><td>     </td></tr>\n",
       "</tbody>\n",
       "</table><br>Number of errored trials: 1<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name                </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                         </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_TradingEnv_a84c7_00000</td><td style=\"text-align: right;\">           1</td><td>C:\\Users\\mathe\\ray_results\\MyExperiment1\\PPO_TradingEnv_a84c7_00000_0_2022-04-22_14-14-24\\error.txt</td></tr>\n",
       "</tbody>\n",
       "</table><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=23632)\u001b[0m 2022-04-22 14:14:44,276\tERROR worker.py:431 -- Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::PPO.__init__()\u001b[39m (pid=23632, ip=127.0.0.1)\n",
      " pid=23632)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 625, in ray._raylet.execute_task\n",
      " pid=23632)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 629, in ray._raylet.execute_task\n",
      " pid=23632)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 578, in ray._raylet.execute_task.function_executor\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\function_manager.py\", line 609, in actor_method_executor\n",
      " pid=23632)\u001b[0m     return method(__ray_actor, *args, **kwargs)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      " pid=23632)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 102, in __init__\n",
      " pid=23632)\u001b[0m     Trainer.__init__(self, config, env, logger_creator,\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 661, in __init__\n",
      " pid=23632)\u001b[0m     super().__init__(config, logger_creator, remote_checkpoint_dir,\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\tune\\trainable.py\", line 121, in __init__\n",
      " pid=23632)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      " pid=23632)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 113, in setup\n",
      " pid=23632)\u001b[0m     super().setup(config)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 764, in setup\n",
      " pid=23632)\u001b[0m     self._init(self.config, self.env_creator)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      " pid=23632)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer_template.py\", line 136, in _init\n",
      " pid=23632)\u001b[0m     self.workers = self._make_workers(\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\util\\tracing\\tracing_helper.py\", line 451, in _resume_span\n",
      " pid=23632)\u001b[0m     return method(self, *_args, **_kwargs)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\agents\\trainer.py\", line 1727, in _make_workers\n",
      " pid=23632)\u001b[0m     return WorkerSet(\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\rllib\\evaluation\\worker_set.py\", line 87, in __init__\n",
      " pid=23632)\u001b[0m     remote_spaces = ray.get(self.remote_workers(\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\client_mode_hook.py\", line 105, in wrapper\n",
      " pid=23632)\u001b[0m     return func(*args, **kwargs)\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\worker.py\", line 1713, in get\n",
      " pid=23632)\u001b[0m     raise value.as_instanceof_cause()\n",
      " pid=23632)\u001b[0m ray.exceptions.RayTaskError(RayOutOfMemoryError): \u001b[36mray::RolloutWorker.foreach_policy()\u001b[39m (pid=24456, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x00000239D83C5C70>)\n",
      " pid=23632)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 585, in ray._raylet.execute_task\n",
      " pid=23632)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 156, in raise_if_low_memory\n",
      " pid=23632)\u001b[0m     raise RayOutOfMemoryError(\n",
      " pid=23632)\u001b[0m ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-625611C is used (15.59 / 15.86 GB). The top 10 memory consumers are:\n",
      " pid=23632)\u001b[0m \n",
      " pid=23632)\u001b[0m PID\tMEM\tCOMMAND\n",
      " pid=23632)\u001b[0m 16600\t2.88GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe -m ipykernel_launcher --ip=127.0.0.1 --stdin=9014 --cont\n",
      " pid=23632)\u001b[0m 1776\t1.95GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --type=renderer --user-data-dir=C:\\\n",
      " pid=23632)\u001b[0m 19044\t1.83GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      " pid=23632)\u001b[0m 24456\t0.78GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      " pid=23632)\u001b[0m 36580\t0.45GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe -m ipykernel_launcher --ip=127.0.0.1 --stdin=9019 --cont\n",
      " pid=23632)\u001b[0m 23632\t0.41GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      " pid=23632)\u001b[0m 16340\t0.26GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --type=renderer --user-data-dir=C:\\\n",
      " pid=23632)\u001b[0m 13716\t0.21GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      " pid=23632)\u001b[0m 17216\t0.19GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --ms-enable-electron-run-as-node c:\n",
      " pid=23632)\u001b[0m 10024\t0.18GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --ms-enable-electron-run-as-node c:\n",
      " pid=23632)\u001b[0m \n",
      " pid=23632)\u001b[0m In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      " pid=23632)\u001b[0m ---\n",
      " pid=23632)\u001b[0m --- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      " pid=23632)\u001b[0m --- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      " pid=23632)\u001b[0m ---\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [PPO_TradingEnv_a84c7_00000])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_36580/2817722470.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m }\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m analysis = tune.run(\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;31m# We'll be using the builtin PPO agent in RLLib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mrun_or_experiment\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"PPO\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, queue_trials, loggers, _remote)\u001b[0m\n\u001b[0;32m    618\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [PPO_TradingEnv_a84c7_00000])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " pid=39976)\u001b[0m 2022-04-22 14:23:14,882\tINFO trainer.py:712 -- Executing eagerly (framework='tf2'), with eager_tracing=False. For production workloads, make sure to set `eager_tracing=True` in order to match the speed of tf-static-graph (framework='tf'). For debugging purposes, `eager_tracing=False` is the best choice.\n",
      " pid=39972)\u001b[0m 2022-04-22 14:23:20,600\tINFO rollout_worker.py:1705 -- Validating sub-env at vector index=0 ... (ok)\n",
      " pid=39972)\u001b[0m 2022-04-22 14:23:20,664\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      " pid=39972)\u001b[0m 2022-04-22 14:23:20,671\tDEBUG catalog.py:706 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x000001F4F7712130>: Box([[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39972)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]], [[inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39972)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]], (20, 10), float32) -> (20, 10)\n",
      " pid=39972)\u001b[0m 2022-04-22 14:23:20,687\tINFO eager_tf_policy.py:308 -- TF-eager Policy (worker=1) running on GPU.\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:22,190\tINFO worker_set.py:104 -- Inferred observation/action spaces from remote worker (local worker has no env): {'default_policy': (Box([[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]], [[inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]], (20, 10), float32), Discrete(21)), '__env__': (Box([[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]], [[inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]], (20, 10), float32), Discrete(21))}\n",
      " pid=39972)\u001b[0m 2022-04-22 14:23:22,169\tDEBUG rollout_worker.py:728 -- Created rollout worker with env <ray.rllib.env.base_env._VectorEnvToBaseEnv object at 0x000001F4F76F3FD0> (<TradingEnv instance>), policies {}\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:22,234\tDEBUG rollout_worker.py:1534 -- Creating policy for default_policy\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:22,240\tDEBUG catalog.py:706 -- Created preprocessor <ray.rllib.models.preprocessors.NoPreprocessor object at 0x0000015257C36850>: Box([[-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]\n",
      " pid=39976)\u001b[0m  [-inf -inf -inf -inf -inf -inf -inf -inf -inf -inf]], [[inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]\n",
      " pid=39976)\u001b[0m  [inf inf inf inf inf inf inf inf inf inf]], (20, 10), float32) -> (20, 10)\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:22,255\tINFO eager_tf_policy.py:308 -- TF-eager Policy (worker=local) running on GPU.\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:25,456\tINFO rollout_worker.py:1555 -- Built policy map: {}\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:25,458\tINFO rollout_worker.py:1556 -- Built preprocessor map: {'default_policy': <ray.rllib.models.preprocessors.NoPreprocessor object at 0x0000015257C36850>}\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:25,459\tINFO rollout_worker.py:618 -- Built filter map: {'default_policy': MeanStdFilter((20, 10), True, True, None, (n=0, mean_mean=0.0, mean_std=0.0), (n=0, mean_mean=0.0, mean_std=0.0))}\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:25,459\tDEBUG rollout_worker.py:728 -- Created rollout worker with env None (None), policies {}\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:25,478\tINFO trainable.py:124 -- Trainable.setup took 11.638 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:25,480\tWARNING util.py:57 -- Install gputil for GPU system monitoring.\n",
      " pid=39976)\u001b[0m 2022-04-22 14:23:26,660\tERROR worker.py:84 -- Unhandled error (suppress with RAY_IGNORE_UNHANDLED_ERRORS=1): \u001b[36mray::RolloutWorker.set_weights()\u001b[39m (pid=39972, ip=127.0.0.1, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x000001F4F4E70F40>)\n",
      " pid=39976)\u001b[0m   File \"python\\ray\\_raylet.pyx\", line 585, in ray._raylet.execute_task\n",
      " pid=39976)\u001b[0m   File \"C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\_private\\memory_monitor.py\", line 156, in raise_if_low_memory\n",
      " pid=39976)\u001b[0m     raise RayOutOfMemoryError(\n",
      " pid=39976)\u001b[0m ray._private.memory_monitor.RayOutOfMemoryError: More than 95% of the memory on node DESKTOP-625611C is used (15.82 / 15.86 GB). The top 10 memory consumers are:\n",
      " pid=39976)\u001b[0m \n",
      " pid=39976)\u001b[0m PID\tMEM\tCOMMAND\n",
      " pid=39976)\u001b[0m 16600\t3.13GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe -m ipykernel_launcher --ip=127.0.0.1 --stdin=9014 --cont\n",
      " pid=39976)\u001b[0m 1776\t1.96GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --type=renderer --user-data-dir=C:\\\n",
      " pid=39976)\u001b[0m 39972\t1.36GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      " pid=39976)\u001b[0m 19044\t1.05GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      " pid=39976)\u001b[0m 39976\t0.79GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe C:\\Users\\mathe\\anaconda3\\envs\\tf\\lib\\site-packages\\ray\\w\n",
      " pid=39976)\u001b[0m 36580\t0.45GiB\tC:\\Users\\mathe\\anaconda3\\envs\\tf\\python.exe -m ipykernel_launcher --ip=127.0.0.1 --stdin=9019 --cont\n",
      " pid=39976)\u001b[0m 16340\t0.28GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --type=renderer --user-data-dir=C:\\\n",
      " pid=39976)\u001b[0m 17216\t0.2GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --ms-enable-electron-run-as-node c:\n",
      " pid=39976)\u001b[0m 13716\t0.16GiB\tC:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe --no-startup-window --win-session-start\n",
      " pid=39976)\u001b[0m 10024\t0.13GiB\tC:\\Users\\mathe\\AppData\\Local\\Programs\\Microsoft VS Code\\Code.exe --ms-enable-electron-run-as-node c:\n",
      " pid=39976)\u001b[0m \n",
      " pid=39976)\u001b[0m In addition, up to 0.0 GiB of shared memory is currently being used by the Ray object store.\n",
      " pid=39976)\u001b[0m ---\n",
      " pid=39976)\u001b[0m --- Tip: Use the `ray memory` command to list active objects in the cluster.\n",
      " pid=39976)\u001b[0m --- To disable OOM exceptions, set RAY_DISABLE_MEMORY_MONITOR=1.\n",
      " pid=39976)\u001b[0m ---\n",
      "2022-04-22 14:33:15,911\tERROR worker.py:1247 -- listen_error_messages_raylet: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto\n",
      "2022-04-22 14:33:15,917\tERROR import_thread.py:89 -- ImportThread: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto\n",
      "2022-04-22 14:33:15,920\tERROR worker.py:478 -- print_logs: [WinError 10054] Foi forçado o cancelamento de uma conexão existente pelo host remoto\n"
     ]
    }
   ],
   "source": [
    "env_config_training = {\n",
    "    # We want to look at the last 14 samples (hours)\n",
    "    \"window_size\": 7 * 5, # hours * days\n",
    "    # And calculate reward based on the actions taken in the next 7 hours\n",
    "    #\"reward_window_size\": 7,\n",
    "    # If it goes past 10% loss during the iteration, we don't want to waste time on a \"loser\".\n",
    "    \"max_allowed_loss\": 0.10,\n",
    "}\n",
    "\n",
    "analysis = tune.run(\n",
    "    # We'll be using the builtin PPO agent in RLLib\n",
    "    run_or_experiment=\"PPO\",\n",
    "    name=\"MyExperiment1\",\n",
    "    metric='episode_reward_mean',\n",
    "    stop={\n",
    "      \"episode_reward_mean\": 0.05\n",
    "    },\n",
    "    config={\n",
    "        \"env\": \"TradingEnv\",\n",
    "        \"env_config\": env_config_training,\n",
    "        \"log_level\": \"WARNING\",\n",
    "        \"framework\": \"tf2\",\n",
    "        \"eager_tracing\": True,\n",
    "        \"ignore_worker_failures\": True,\n",
    "        \"num_workers\": 1,\n",
    "        \"num_gpus\": 1,\n",
    "        \"clip_rewards\": True,\n",
    "        \"lr\": 8e-6,\n",
    "        \"lr_schedule\": [\n",
    "            [0, 1e-1],\n",
    "            [int(1e2), 1e-2],\n",
    "            [int(1e3), 1e-3],\n",
    "            [int(1e4), 1e-4],\n",
    "            [int(1e5), 1e-5],\n",
    "            [int(1e6), 1e-6],\n",
    "            [int(1e7), 1e-7]\n",
    "        ],\n",
    "        \"gamma\": 0,\n",
    "        \"observation_filter\": \"MeanStdFilter\",\n",
    "        \"lambda\": 0.72,\n",
    "        \"vf_loss_coeff\": 0.5,\n",
    "        \"entropy_coeff\": 0.01\n",
    "    },\n",
    "    checkpoint_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822aba60",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e085ee7c",
   "metadata": {},
   "source": [
    "After training is complete, we would now like to get access to the agents policy. We can do that by restoring the agent using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get checkpoint\n",
    "checkpoints = analysis.get_trial_checkpoints_paths(\n",
    "    trial=analysis.get_best_trial(\"episode_reward_mean\", mode=\"max\"),\n",
    "    metric=\"episode_reward_mean\"    \n",
    ")\n",
    "\n",
    "checkpoint_path = checkpoints[0][0]\n",
    "\n",
    "# Restore agent\n",
    "agent = ppo.PPOTrainer(\n",
    "    env=\"TradingEnv\",\n",
    "    config={\n",
    "        \"env_config\": env_config_training,\n",
    "        \"log_level\": \"DEBUG\",\n",
    "        \"framework\": \"tf2\",\n",
    "        \"ignore_worker_failures\": True,\n",
    "        \"num_workers\": 1,\n",
    "        \"num_gpus\": 1,\n",
    "        \"clip_rewards\": True,\n",
    "        \"lr\": 8e-6,\n",
    "        \"lr_schedule\": [\n",
    "            [0, 1e-1],\n",
    "            [int(1e2), 1e-2],\n",
    "            [int(1e3), 1e-3],\n",
    "            [int(1e4), 1e-4],\n",
    "            [int(1e5), 1e-5],\n",
    "            [int(1e6), 1e-6],\n",
    "            [int(1e7), 1e-7]\n",
    "        ],\n",
    "        \"gamma\": 0,\n",
    "        \"observation_filter\": \"MeanStdFilter\",\n",
    "        \"model\": {\n",
    "            \"fcnet_hiddens\": [256, 256], # Hyperparameter grid search defined above\n",
    "        },\n",
    "        \"lambda\": 0.72,\n",
    "        \"vf_loss_coeff\": 0.5,\n",
    "        \"entropy_coeff\": 0.01\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aaf43f2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e1a0aa",
   "metadata": {},
   "source": [
    "After training is complete, we would now like to get access to the agents policy. We can do that by restoring the agent using the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504db828",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 7 * 5\n",
    "\n",
    "# Restore agent\n",
    "agent.restore(checkpoint_path)\n",
    "\n",
    "# Instantiate the environment\n",
    "env = create_training_env({\n",
    "    \"window_size\": window_size,\n",
    "    #\"reward_window_size\": 7\n",
    "})\n",
    "\n",
    "# Run until episode ends\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = agent.compute_single_action(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c5600",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5f04b2",
   "metadata": {},
   "source": [
    "### Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e86b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_eval_env(config):\n",
    "    \"\"\"Creates the Evaluation Environment.\"\"\"\n",
    "    dataset = pd.read_csv(filepath_or_buffer=\"C:\\\\Users\\\\mathe\\\\Desktop\\\\Desktop\\\\Estudos\\\\Courses\\\\(Framework) TensorTrade\\\\evaluation.csv\", \n",
    "                          parse_dates=True).fillna(method='backfill').fillna(method='ffill')\n",
    "    \n",
    "    # Price Series\n",
    "    price = Stream.source(list(dataset[\"Close\"]), dtype=\"float\").rename(\"BRL-ASSETS\")\n",
    "    \n",
    "    b3_commission = 0.0035\n",
    "    b3_options = ExchangeOptions(commission=b3_commission)\n",
    "    b3_exchange = Exchange(\"B3\", service=execute_order, options=b3_options)(price)\n",
    "    \n",
    "    # Instruments\n",
    "    BRL = Instrument(\"BRL\", 2, \"Brazilian Currency\")\n",
    "    ASSETS = Instrument(\"ASSETS\", , \"Assets\")\n",
    "\n",
    "    # Portfolio\n",
    "    cash = Wallet(b3_exchange, 1000 * BRL) # Money\n",
    "    asset = Wallet(b3_exchange, 0 * ASSETS) # Stocks/Assets\n",
    "    \n",
    "    portfolio = Portfolio(BRL, [cash, asset])\n",
    "    \n",
    "    features = []\n",
    "    for c in dataset.columns[1:]:\n",
    "        s = Stream.source(list(dataset[c]), dtype=\"float\").rename(dataset[c].name)\n",
    "        features += [s]\n",
    "    feed = DataFeed(features)\n",
    "    feed.compile()\n",
    "    \n",
    "#     # Reward\n",
    "#     reward_scheme = PBR(price=price)\n",
    "    \n",
    "#     # Actions\n",
    "#     action_scheme = BSH(\n",
    "#         cash=cash,\n",
    "#         asset=asset\n",
    "#     ).attach(reward_scheme)\n",
    "\n",
    "    reward_scheme = default.actions.SimpleOrders()\n",
    "    \n",
    "    action_scheme = default.rewards.SimpleProfit()#.attach(reward_scheme)\n",
    "    \n",
    "    # Visualization\n",
    "    renderer_feed = DataFeed([\n",
    "        Stream.source(list(dataset.index)).rename(\"date\"),\n",
    "        Stream.source(list(dataset[\"Close\"]), dtype=\"float\").rename(\"price\"),\n",
    "        Stream.sensor(action_scheme, lambda s: s.action, dtype=\"float\").rename(\"action\")\n",
    "    ])\n",
    "\n",
    "    environment = default.create(\n",
    "        feed=feed,\n",
    "        portfolio=portfolio,\n",
    "        action_scheme=reward_scheme,\n",
    "        reward_scheme=action_scheme,\n",
    "        renderer_feed=renderer_feed,\n",
    "        renderer=PositionChangeChart(),\n",
    "        window_size=config[\"window_size\"],\n",
    "        max_allowed_loss=0.4\n",
    "    )\n",
    "    \n",
    "    return environment, portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cc161d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(filepath_or_buffer=\"C:\\\\Users\\\\mathe\\\\Desktop\\\\Desktop\\\\Estudos\\\\Courses\\\\(Framework) TensorTrade\\\\evaluation.csv\", \n",
    "                      parse_dates=True).fillna(method='backfill').fillna(method='ffill')\n",
    "    \n",
    "# PRICES\n",
    "price_eval = Stream.source(list(dataset[\"Close\"]), dtype=\"float\").rename(\"BRL-TTC\")\n",
    "\n",
    "# Instantiate the environment\n",
    "env, portfolio = create_eval_env({\n",
    "    \"window_size\": 14\n",
    "})\n",
    "\n",
    "# Run until episode ends\n",
    "episode_reward = 0\n",
    "done = False\n",
    "obs = env.reset()\n",
    "\n",
    "while not done:\n",
    "    action = agent.compute_single_action(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    episode_reward += reward\n",
    "    \n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b164a8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio.ledger.as_frame().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaa4025",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(portfolio.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc603aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.T.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdbf42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"net_worth\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dff236",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"B3:/BRL-ASSETS\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a073c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[\"B3:/ASSETS:/worth\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "worth_streams = []\n",
    "for wallet in portfolio.wallets:\n",
    "    total_balance = Stream.sensor(\n",
    "        wallet,\n",
    "        lambda w: w.total_balance.as_float(),\n",
    "        dtype=\"float\"\n",
    "    )\n",
    "    \n",
    "    symbol = wallet.instrument.symbol\n",
    "\n",
    "    if symbol == portfolio.base_instrument.symbol:\n",
    "        worth_streams += [total_balance]\n",
    "    else:\n",
    "        price = Stream.select(\n",
    "        wallet.exchange.streams(),\n",
    "            lambda s: s.name.endswith(symbol)\n",
    "        )\n",
    "        worth_streams += [(price * total_balance)]\n",
    "\n",
    "net_worth = Stream.reduce(worth_streams).sum().rename(\"net_worth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa2b429",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
